{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Hw4_4090",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cbowler1234/ECGR4090_Tabkhi_Hw/blob/main/Hw4/Hw4_4090.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qSCN97Yav6P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ad2dfee-01ce-4ade-afd5-d715bd165c80"
      },
      "source": [
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "torch.set_printoptions(edgeitems=2)\n",
        "torch.manual_seed(123)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f1720ced790>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FoU7L-H0av6Q"
      },
      "source": [
        "class_names = ['airplane','automobile','bird','cat','deer',\n",
        "               'dog','frog','horse','ship','truck']"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1V0za8QWkRmE",
        "outputId": "ee1a5213-91dc-404b-9644-4ad9d63c2d1b"
      },
      "source": [
        "\n",
        "device = (torch.device('cuda') if torch.cuda.is_available()\n",
        "else torch.device('cpu'))\n",
        "print(f\"Training on device {device}.\")"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on device cuda.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvHNhzpQav6Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d795c047-6afc-4c73-f940-01bab4161a8d"
      },
      "source": [
        "from torchvision import datasets, transforms\n",
        "data_path = '../data-unversioned/p1ch7/'\n",
        "cifar10 = datasets.CIFAR10(\n",
        "    data_path, train=True, download=True,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
        "                             (0.2470, 0.2435, 0.2616))\n",
        "    ]))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsxymtPUav6R"
      },
      "source": [
        "cifar10_val = datasets.CIFAR10(\n",
        "    data_path, train=False, download=False,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
        "                             (0.2470, 0.2435, 0.2616))\n",
        "    ]))"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7cKe7mGav6R"
      },
      "source": [
        "label_map = {6: 0, 7: 1,8:2,9:3}\n",
        "class_names = ['frog','horse','ship','truck']\n",
        "cifar2 = [(img, label_map[label])\n",
        "          for img, label in cifar10 \n",
        "          if label in [6, 7,8,9]]\n",
        "cifar2_val = [(img, label_map[label])\n",
        "              for img, label in cifar10_val\n",
        "              if label in [6, 7,8,9]]"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaN0e5pKav6R"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "n_out = 2\n",
        "\n",
        "model = nn.Sequential(\n",
        "            nn.Linear(\n",
        "                3072,  # <1>\n",
        "                512,   # <2>\n",
        "            ),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(\n",
        "                512,   # <2>\n",
        "                n_out, # <3>\n",
        "            )\n",
        "        )"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fs6tZysQav6R"
      },
      "source": [
        "def softmax(x):\n",
        "    return torch.exp(x) / torch.exp(x).sum()"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQwXbGEvav6R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bddc7c54-297b-45bd-c29c-7f3920bb9319"
      },
      "source": [
        "x = torch.tensor([1.0, 2.0, 3.0])\n",
        "\n",
        "softmax(x)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0900, 0.2447, 0.6652])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkeMXkdlav6S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ef2dba9-1bc0-402e-c940-57ca5e6f3c64"
      },
      "source": [
        "softmax(x).sum()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DOqnPhDav6S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "066615f3-ee96-4ab0-b104-4779f3f7e462"
      },
      "source": [
        "softmax = nn.Softmax(dim=1)\n",
        "\n",
        "x = torch.tensor([[1.0, 2.0, 3.0],\n",
        "                  [1.0, 2.0, 3.0]])\n",
        "\n",
        "softmax(x)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0900, 0.2447, 0.6652],\n",
              "        [0.0900, 0.2447, 0.6652]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bc7DpPoMav6S"
      },
      "source": [
        "model = nn.Sequential(\n",
        "            nn.Linear(3072, 512),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(512, 2),\n",
        "            nn.Softmax(dim=1))"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRcnmcaoav6S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "213980d0-5dde-4039-e585-11fa186222ac"
      },
      "source": [
        "img, _ = cifar2[0]\n",
        "\n",
        "plt.imshow(img.permute(1, 2, 0))\n",
        "plt.show()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xfs0h3owav6S"
      },
      "source": [
        "img_batch = img.view(-1).unsqueeze(0)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkTmQOYQav6S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e4f193e-ead4-48ef-ae94-ccb67ce567e0"
      },
      "source": [
        "out = model(img_batch)\n",
        "out"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4813, 0.5187]], grad_fn=<SoftmaxBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwtUx9oOav6T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97973d98-cda6-4926-b79d-28fa3dd9686d"
      },
      "source": [
        "_, index = torch.max(out, dim=1)\n",
        "\n",
        "index"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhPs813yav6T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc64fb66-bdcf-4e0c-c56c-e88a2b9cbc37"
      },
      "source": [
        "out = torch.tensor([\n",
        "    [0.6, 0.4],\n",
        "    [0.9, 0.1],\n",
        "    [0.3, 0.7],\n",
        "    [0.2, 0.8],\n",
        "])\n",
        "class_index = torch.tensor([0, 0, 1, 1]).unsqueeze(1)\n",
        "\n",
        "truth = torch.zeros((4,2))\n",
        "truth.scatter_(dim=1, index=class_index, value=1.0)\n",
        "truth"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0.],\n",
              "        [1., 0.],\n",
              "        [0., 1.],\n",
              "        [0., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7XakMThav6T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5db237a-702a-4d01-c404-a1210ed6f520"
      },
      "source": [
        "def mse(out):\n",
        "    return ((out - truth) ** 2).sum(dim=1).mean()\n",
        "mse(out)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1500)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TkJmNgpav6T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bec693a-65a0-402a-e777-216c5e5ff240"
      },
      "source": [
        "out.gather(dim=1, index=class_index)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.6000],\n",
              "        [0.9000],\n",
              "        [0.7000],\n",
              "        [0.8000]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzXqhl76av6T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a52a44ee-9ec5-46f2-a6f6-b0a13f800add"
      },
      "source": [
        "def likelihood(out):\n",
        "    prod = 1.0\n",
        "    for x in out.gather(dim=1, index=class_index):\n",
        "        prod *= x\n",
        "    return prod\n",
        "\n",
        "likelihood(out)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.3024])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctOxaZjxav6T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6134147-5231-4e5f-9f55-59fe38084f30"
      },
      "source": [
        "def neg_log_likelihood(out):\n",
        "    return -likelihood(out).log()\n",
        "\n",
        "neg_log_likelihood(out)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.1960])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVuPSGauav6U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3d3d2cb-4a2d-4b12-c264-7612bfa07332"
      },
      "source": [
        "out0 = out.clone().detach()\n",
        "out0[0] = torch.tensor([0.9, 0.1]) # more right\n",
        "\n",
        "out2 = out.clone().detach()\n",
        "out2[0] = torch.tensor([0.4, 0.6]) # slightly wrong\n",
        "\n",
        "out3 = out.clone().detach()\n",
        "out3[0] = torch.tensor([0.1, 0.9]) # very wrong\n",
        "\n",
        "mse_comparison = torch.tensor([mse(o) for o in [out0, out, out2, out3]])\n",
        "mse_comparison"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0750, 0.1500, 0.2500, 0.4750])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6mQ-aPUav6U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e841e534-159d-4d8b-dbdc-b6dc6206cd07"
      },
      "source": [
        "((mse_comparison / mse_comparison[1]) - 1) * 100"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-50.0000,   0.0000,  66.6667, 216.6667])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivFj8AOVav6U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f82d7d9-774b-4033-8141-6f6b3bf3409c"
      },
      "source": [
        "nll_comparison = torch.tensor([neg_log_likelihood(o) \n",
        "                               for o in [out0, out, out2, out3]])\n",
        "nll_comparison"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.7905, 1.1960, 1.6015, 2.9878])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IblAbFuwav6U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02967ccf-e6d2-4e6d-b473-43207928eb98"
      },
      "source": [
        "((nll_comparison / nll_comparison[1]) - 1) * 100"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-33.9016,   0.0000,  33.9016, 149.8121])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-cas48Gav6U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a530475-3aeb-45c2-e63f-ff34c51aecb1"
      },
      "source": [
        "softmax = nn.Softmax(dim=1)\n",
        "\n",
        "log_softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "x = torch.tensor([[0.0, 104.0]])\n",
        "\n",
        "softmax(x)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoAFIjPXav6U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "666c997f-db89-40b3-cf8d-4995affe111f"
      },
      "source": [
        "softmax = nn.Softmax(dim=1)\n",
        "\n",
        "log_softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "x = torch.tensor([[0.0, 104.0]])\n",
        "\n",
        "softmax(x)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rRGwalnav6U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13cb5399-1e62-4ee0-e7c9-3f517097a56e"
      },
      "source": [
        "torch.log(softmax(x))"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-inf, 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBdWbejGav6V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17c4753c-9999-4a33-c5cd-1076302edde7"
      },
      "source": [
        "log_softmax(x)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-104.,    0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bn84fAN0av6V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f616570-0b72-4a43-8163-3e0a19cf2ba5"
      },
      "source": [
        "torch.exp(log_softmax(x))"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QmmB8cMav6V"
      },
      "source": [
        "model = nn.Sequential(\n",
        "            nn.Linear(3072, 512),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(512, 2),\n",
        "            nn.LogSoftmax(dim=1))"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMNR_E2Qav6V"
      },
      "source": [
        "loss = nn.NLLLoss()"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1bifxp1av6V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c57cf1c-bec0-44f5-c5b5-8cccc9443968"
      },
      "source": [
        "img, label = cifar2[0]\n",
        "\n",
        "out = model(img.view(-1).unsqueeze(0))\n",
        "\n",
        "loss(out, torch.tensor([label]))"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.8378, grad_fn=<NllLossBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMu4IBQBav6V"
      },
      "source": [
        ""
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhZShUCGav6V"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
        "                                           shuffle=True)"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtpPRJ-sav6W"
      },
      "source": [
        ""
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAl8v2Clav6W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00447d5d-9965-4e1a-a5e3-cb2def8aea61"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import time\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
        "                                           shuffle=True)\n",
        "\n",
        "model = nn.Sequential(\n",
        "            nn.Linear(3072, 512),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(512, 4),\n",
        "            nn.LogSoftmax(dim=1)).to(device=device)\n",
        "\n",
        "learning_rate = 1e-2\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "loss_fn = nn.NLLLoss()\n",
        "\n",
        "n_epochs = 200\n",
        "start=time.time()\n",
        "for epoch in range(n_epochs):\n",
        "    for imgs, labels in train_loader:\n",
        "        imgs = imgs.to(device=device)\n",
        "        labels = labels.to(device=device)\n",
        "        outputs = model(imgs.view(imgs.shape[0], -1))\n",
        "        loss = loss_fn(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))\n",
        "stop=time.time()\n",
        "duration= stop-start\n",
        "print(duration)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0, Loss: 0.709550\n",
            "Epoch: 1, Loss: 0.619307\n",
            "Epoch: 2, Loss: 1.054392\n",
            "Epoch: 3, Loss: 0.710791\n",
            "Epoch: 4, Loss: 0.594423\n",
            "Epoch: 5, Loss: 0.531334\n",
            "Epoch: 6, Loss: 0.473141\n",
            "Epoch: 7, Loss: 0.596265\n",
            "Epoch: 8, Loss: 0.741933\n",
            "Epoch: 9, Loss: 0.386836\n",
            "Epoch: 10, Loss: 0.624176\n",
            "Epoch: 11, Loss: 0.413143\n",
            "Epoch: 12, Loss: 0.465522\n",
            "Epoch: 13, Loss: 0.518968\n",
            "Epoch: 14, Loss: 0.347353\n",
            "Epoch: 15, Loss: 0.521088\n",
            "Epoch: 16, Loss: 0.405736\n",
            "Epoch: 17, Loss: 0.237977\n",
            "Epoch: 18, Loss: 0.456190\n",
            "Epoch: 19, Loss: 0.254552\n",
            "Epoch: 20, Loss: 0.512944\n",
            "Epoch: 21, Loss: 0.229965\n",
            "Epoch: 22, Loss: 0.293783\n",
            "Epoch: 23, Loss: 0.346775\n",
            "Epoch: 24, Loss: 0.264755\n",
            "Epoch: 25, Loss: 0.247713\n",
            "Epoch: 26, Loss: 0.150990\n",
            "Epoch: 27, Loss: 0.111717\n",
            "Epoch: 28, Loss: 0.209370\n",
            "Epoch: 29, Loss: 0.215649\n",
            "Epoch: 30, Loss: 0.218999\n",
            "Epoch: 31, Loss: 0.092625\n",
            "Epoch: 32, Loss: 0.133992\n",
            "Epoch: 33, Loss: 0.150693\n",
            "Epoch: 34, Loss: 0.141198\n",
            "Epoch: 35, Loss: 0.178996\n",
            "Epoch: 36, Loss: 0.202224\n",
            "Epoch: 37, Loss: 0.133415\n",
            "Epoch: 38, Loss: 0.144692\n",
            "Epoch: 39, Loss: 0.104609\n",
            "Epoch: 40, Loss: 0.100985\n",
            "Epoch: 41, Loss: 0.077254\n",
            "Epoch: 42, Loss: 0.073344\n",
            "Epoch: 43, Loss: 0.059027\n",
            "Epoch: 44, Loss: 0.049943\n",
            "Epoch: 45, Loss: 0.040082\n",
            "Epoch: 46, Loss: 0.084346\n",
            "Epoch: 47, Loss: 0.052942\n",
            "Epoch: 48, Loss: 0.057660\n",
            "Epoch: 49, Loss: 0.229930\n",
            "Epoch: 50, Loss: 0.094425\n",
            "Epoch: 51, Loss: 0.032227\n",
            "Epoch: 52, Loss: 0.043244\n",
            "Epoch: 53, Loss: 0.074454\n",
            "Epoch: 54, Loss: 0.034664\n",
            "Epoch: 55, Loss: 0.029166\n",
            "Epoch: 56, Loss: 0.036464\n",
            "Epoch: 57, Loss: 0.067764\n",
            "Epoch: 58, Loss: 0.040311\n",
            "Epoch: 59, Loss: 0.044776\n",
            "Epoch: 60, Loss: 0.057284\n",
            "Epoch: 61, Loss: 0.067487\n",
            "Epoch: 62, Loss: 0.035396\n",
            "Epoch: 63, Loss: 0.029182\n",
            "Epoch: 64, Loss: 0.024010\n",
            "Epoch: 65, Loss: 0.031110\n",
            "Epoch: 66, Loss: 0.019231\n",
            "Epoch: 67, Loss: 0.041497\n",
            "Epoch: 68, Loss: 0.026657\n",
            "Epoch: 69, Loss: 0.032097\n",
            "Epoch: 70, Loss: 0.022802\n",
            "Epoch: 71, Loss: 0.024925\n",
            "Epoch: 72, Loss: 0.044309\n",
            "Epoch: 73, Loss: 0.015214\n",
            "Epoch: 74, Loss: 0.028832\n",
            "Epoch: 75, Loss: 0.020800\n",
            "Epoch: 76, Loss: 0.049375\n",
            "Epoch: 77, Loss: 0.012326\n",
            "Epoch: 78, Loss: 0.034933\n",
            "Epoch: 79, Loss: 0.017198\n",
            "Epoch: 80, Loss: 0.020426\n",
            "Epoch: 81, Loss: 0.011507\n",
            "Epoch: 82, Loss: 0.028264\n",
            "Epoch: 83, Loss: 0.013732\n",
            "Epoch: 84, Loss: 0.027373\n",
            "Epoch: 85, Loss: 0.024396\n",
            "Epoch: 86, Loss: 0.012922\n",
            "Epoch: 87, Loss: 0.013622\n",
            "Epoch: 88, Loss: 0.016281\n",
            "Epoch: 89, Loss: 0.014455\n",
            "Epoch: 90, Loss: 0.006525\n",
            "Epoch: 91, Loss: 0.013736\n",
            "Epoch: 92, Loss: 0.028667\n",
            "Epoch: 93, Loss: 0.009951\n",
            "Epoch: 94, Loss: 0.016107\n",
            "Epoch: 95, Loss: 0.015576\n",
            "Epoch: 96, Loss: 0.016346\n",
            "Epoch: 97, Loss: 0.015579\n",
            "Epoch: 98, Loss: 0.013943\n",
            "Epoch: 99, Loss: 0.009965\n",
            "Epoch: 100, Loss: 0.007755\n",
            "Epoch: 101, Loss: 0.010565\n",
            "Epoch: 102, Loss: 0.012208\n",
            "Epoch: 103, Loss: 0.012747\n",
            "Epoch: 104, Loss: 0.007818\n",
            "Epoch: 105, Loss: 0.008867\n",
            "Epoch: 106, Loss: 0.012475\n",
            "Epoch: 107, Loss: 0.012214\n",
            "Epoch: 108, Loss: 0.018660\n",
            "Epoch: 109, Loss: 0.011288\n",
            "Epoch: 110, Loss: 0.007898\n",
            "Epoch: 111, Loss: 0.007036\n",
            "Epoch: 112, Loss: 0.016638\n",
            "Epoch: 113, Loss: 0.005393\n",
            "Epoch: 114, Loss: 0.006941\n",
            "Epoch: 115, Loss: 0.011989\n",
            "Epoch: 116, Loss: 0.009212\n",
            "Epoch: 117, Loss: 0.010463\n",
            "Epoch: 118, Loss: 0.005809\n",
            "Epoch: 119, Loss: 0.012158\n",
            "Epoch: 120, Loss: 0.006897\n",
            "Epoch: 121, Loss: 0.008234\n",
            "Epoch: 122, Loss: 0.006677\n",
            "Epoch: 123, Loss: 0.012033\n",
            "Epoch: 124, Loss: 0.010284\n",
            "Epoch: 125, Loss: 0.007052\n",
            "Epoch: 126, Loss: 0.006283\n",
            "Epoch: 127, Loss: 0.009631\n",
            "Epoch: 128, Loss: 0.009207\n",
            "Epoch: 129, Loss: 0.005579\n",
            "Epoch: 130, Loss: 0.004827\n",
            "Epoch: 131, Loss: 0.005322\n",
            "Epoch: 132, Loss: 0.006578\n",
            "Epoch: 133, Loss: 0.007776\n",
            "Epoch: 134, Loss: 0.012663\n",
            "Epoch: 135, Loss: 0.011044\n",
            "Epoch: 136, Loss: 0.004683\n",
            "Epoch: 137, Loss: 0.004524\n",
            "Epoch: 138, Loss: 0.011658\n",
            "Epoch: 139, Loss: 0.006833\n",
            "Epoch: 140, Loss: 0.007669\n",
            "Epoch: 141, Loss: 0.007995\n",
            "Epoch: 142, Loss: 0.005243\n",
            "Epoch: 143, Loss: 0.008800\n",
            "Epoch: 144, Loss: 0.009019\n",
            "Epoch: 145, Loss: 0.006848\n",
            "Epoch: 146, Loss: 0.005510\n",
            "Epoch: 147, Loss: 0.005693\n",
            "Epoch: 148, Loss: 0.004989\n",
            "Epoch: 149, Loss: 0.004222\n",
            "Epoch: 150, Loss: 0.007205\n",
            "Epoch: 151, Loss: 0.004535\n",
            "Epoch: 152, Loss: 0.008216\n",
            "Epoch: 153, Loss: 0.004693\n",
            "Epoch: 154, Loss: 0.006675\n",
            "Epoch: 155, Loss: 0.005852\n",
            "Epoch: 156, Loss: 0.004713\n",
            "Epoch: 157, Loss: 0.004037\n",
            "Epoch: 158, Loss: 0.006892\n",
            "Epoch: 159, Loss: 0.006406\n",
            "Epoch: 160, Loss: 0.005940\n",
            "Epoch: 161, Loss: 0.005749\n",
            "Epoch: 162, Loss: 0.006468\n",
            "Epoch: 163, Loss: 0.005477\n",
            "Epoch: 164, Loss: 0.004499\n",
            "Epoch: 165, Loss: 0.004481\n",
            "Epoch: 166, Loss: 0.003427\n",
            "Epoch: 167, Loss: 0.005157\n",
            "Epoch: 168, Loss: 0.007644\n",
            "Epoch: 169, Loss: 0.005238\n",
            "Epoch: 170, Loss: 0.007035\n",
            "Epoch: 171, Loss: 0.008763\n",
            "Epoch: 172, Loss: 0.005253\n",
            "Epoch: 173, Loss: 0.007041\n",
            "Epoch: 174, Loss: 0.004022\n",
            "Epoch: 175, Loss: 0.006643\n",
            "Epoch: 176, Loss: 0.003336\n",
            "Epoch: 177, Loss: 0.005033\n",
            "Epoch: 178, Loss: 0.006900\n",
            "Epoch: 179, Loss: 0.006538\n",
            "Epoch: 180, Loss: 0.003982\n",
            "Epoch: 181, Loss: 0.003552\n",
            "Epoch: 182, Loss: 0.002221\n",
            "Epoch: 183, Loss: 0.002738\n",
            "Epoch: 184, Loss: 0.003413\n",
            "Epoch: 185, Loss: 0.003790\n",
            "Epoch: 186, Loss: 0.004922\n",
            "Epoch: 187, Loss: 0.004666\n",
            "Epoch: 188, Loss: 0.004978\n",
            "Epoch: 189, Loss: 0.005994\n",
            "Epoch: 190, Loss: 0.004729\n",
            "Epoch: 191, Loss: 0.002970\n",
            "Epoch: 192, Loss: 0.003925\n",
            "Epoch: 193, Loss: 0.004102\n",
            "Epoch: 194, Loss: 0.003200\n",
            "Epoch: 195, Loss: 0.003824\n",
            "Epoch: 196, Loss: 0.004151\n",
            "Epoch: 197, Loss: 0.003420\n",
            "Epoch: 198, Loss: 0.004542\n",
            "Epoch: 199, Loss: 0.003332\n",
            "89.65457510948181\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLotH-Tgav6W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2487089-bf0d-479c-8630-af986e456ee9"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
        "                                           shuffle=False)\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in train_loader:\n",
        "        imgs = imgs.to(device=device)\n",
        "        labels = labels.to(device=device)\n",
        "        outputs = model(imgs.view(imgs.shape[0], -1))\n",
        "        _, predicted = torch.max(outputs, dim=1)\n",
        "        total += labels.shape[0]\n",
        "        correct += int((predicted == labels).sum())\n",
        "        \n",
        "print(\"Accuracy: %f\" % (correct / total))"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 1.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyARcG9Yav6W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3434e81-9ef7-43e9-9776-3b5f106b95ee"
      },
      "source": [
        "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64,\n",
        "                                         shuffle=False)\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in val_loader:\n",
        "        imgs = imgs.to(device=device)\n",
        "        labels = labels.to(device=device)\n",
        "        outputs = model(imgs.view(imgs.shape[0], -1))\n",
        "        _, predicted = torch.max(outputs, dim=1)\n",
        "        total += labels.shape[0]\n",
        "        correct += int((predicted == labels).sum())\n",
        "        \n",
        "print(\"Accuracy: %f\" % (correct / total))"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.777750\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syLuTiRjav6X"
      },
      "source": [
        "model = nn.Sequential(\n",
        "            nn.Linear(3072, 1024),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(512, 128),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(128, 4),\n",
        "            nn.LogSoftmax(dim=1))"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9hWEL-6av6X"
      },
      "source": [
        "model = nn.Sequential(\n",
        "            nn.Linear(3072, 1024),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(512, 128),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(128, 4))\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDBitoU0av6X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0df733e-e3a9-4e5f-ab2c-b937070de681"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
        "                                           shuffle=True)\n",
        "\n",
        "model = nn.Sequential(\n",
        "            nn.Linear(3072, 1024),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(512, 128),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(128, 4)).to(device=device)\n",
        "\n",
        "learning_rate = 1e-2\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "n_epochs = 200\n",
        "start=time.time()\n",
        "for epoch in range(n_epochs):\n",
        "    for imgs, labels in train_loader:\n",
        "        imgs = imgs.to(device=device)\n",
        "        labels = labels.to(device=device)\n",
        "        outputs = model(imgs.view(imgs.shape[0], -1))\n",
        "        loss = loss_fn(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))\n",
        "stop=time.time()\n",
        "duration= stop-start\n",
        "print(duration)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0, Loss: 0.742844\n",
            "Epoch: 1, Loss: 0.544447\n",
            "Epoch: 2, Loss: 0.567063\n",
            "Epoch: 3, Loss: 0.596821\n",
            "Epoch: 4, Loss: 0.561172\n",
            "Epoch: 5, Loss: 0.679898\n",
            "Epoch: 6, Loss: 0.563178\n",
            "Epoch: 7, Loss: 0.565844\n",
            "Epoch: 8, Loss: 0.758182\n",
            "Epoch: 9, Loss: 0.928950\n",
            "Epoch: 10, Loss: 0.569579\n",
            "Epoch: 11, Loss: 1.362335\n",
            "Epoch: 12, Loss: 0.642160\n",
            "Epoch: 13, Loss: 0.578659\n",
            "Epoch: 14, Loss: 0.484896\n",
            "Epoch: 15, Loss: 0.361914\n",
            "Epoch: 16, Loss: 0.343126\n",
            "Epoch: 17, Loss: 0.404867\n",
            "Epoch: 18, Loss: 0.245125\n",
            "Epoch: 19, Loss: 0.465430\n",
            "Epoch: 20, Loss: 0.150145\n",
            "Epoch: 21, Loss: 0.417737\n",
            "Epoch: 22, Loss: 0.287738\n",
            "Epoch: 23, Loss: 0.246963\n",
            "Epoch: 24, Loss: 0.230781\n",
            "Epoch: 25, Loss: 0.141826\n",
            "Epoch: 26, Loss: 0.157408\n",
            "Epoch: 27, Loss: 0.383989\n",
            "Epoch: 28, Loss: 0.146882\n",
            "Epoch: 29, Loss: 0.077726\n",
            "Epoch: 30, Loss: 0.048638\n",
            "Epoch: 31, Loss: 0.028776\n",
            "Epoch: 32, Loss: 0.736177\n",
            "Epoch: 33, Loss: 0.035098\n",
            "Epoch: 34, Loss: 0.005579\n",
            "Epoch: 35, Loss: 0.016293\n",
            "Epoch: 36, Loss: 0.017431\n",
            "Epoch: 37, Loss: 0.016961\n",
            "Epoch: 38, Loss: 0.011184\n",
            "Epoch: 39, Loss: 0.007714\n",
            "Epoch: 40, Loss: 0.014618\n",
            "Epoch: 41, Loss: 0.004475\n",
            "Epoch: 42, Loss: 0.011283\n",
            "Epoch: 43, Loss: 0.005297\n",
            "Epoch: 44, Loss: 0.003824\n",
            "Epoch: 45, Loss: 0.003729\n",
            "Epoch: 46, Loss: 0.002130\n",
            "Epoch: 47, Loss: 0.001270\n",
            "Epoch: 48, Loss: 0.003491\n",
            "Epoch: 49, Loss: 0.002618\n",
            "Epoch: 50, Loss: 0.003111\n",
            "Epoch: 51, Loss: 0.009479\n",
            "Epoch: 52, Loss: 0.003701\n",
            "Epoch: 53, Loss: 0.003865\n",
            "Epoch: 54, Loss: 0.003430\n",
            "Epoch: 55, Loss: 0.002515\n",
            "Epoch: 56, Loss: 0.003834\n",
            "Epoch: 57, Loss: 0.001969\n",
            "Epoch: 58, Loss: 0.003300\n",
            "Epoch: 59, Loss: 0.001980\n",
            "Epoch: 60, Loss: 0.001205\n",
            "Epoch: 61, Loss: 0.002316\n",
            "Epoch: 62, Loss: 0.001574\n",
            "Epoch: 63, Loss: 0.001780\n",
            "Epoch: 64, Loss: 0.001129\n",
            "Epoch: 65, Loss: 0.002618\n",
            "Epoch: 66, Loss: 0.000762\n",
            "Epoch: 67, Loss: 0.000614\n",
            "Epoch: 68, Loss: 0.001267\n",
            "Epoch: 69, Loss: 0.001176\n",
            "Epoch: 70, Loss: 0.002622\n",
            "Epoch: 71, Loss: 0.000942\n",
            "Epoch: 72, Loss: 0.001083\n",
            "Epoch: 73, Loss: 0.000794\n",
            "Epoch: 74, Loss: 0.001021\n",
            "Epoch: 75, Loss: 0.001397\n",
            "Epoch: 76, Loss: 0.001139\n",
            "Epoch: 77, Loss: 0.000798\n",
            "Epoch: 78, Loss: 0.000867\n",
            "Epoch: 79, Loss: 0.000662\n",
            "Epoch: 80, Loss: 0.001071\n",
            "Epoch: 81, Loss: 0.000697\n",
            "Epoch: 82, Loss: 0.000441\n",
            "Epoch: 83, Loss: 0.001095\n",
            "Epoch: 84, Loss: 0.001464\n",
            "Epoch: 85, Loss: 0.000641\n",
            "Epoch: 86, Loss: 0.000928\n",
            "Epoch: 87, Loss: 0.001084\n",
            "Epoch: 88, Loss: 0.001330\n",
            "Epoch: 89, Loss: 0.001485\n",
            "Epoch: 90, Loss: 0.000753\n",
            "Epoch: 91, Loss: 0.000764\n",
            "Epoch: 92, Loss: 0.000736\n",
            "Epoch: 93, Loss: 0.000912\n",
            "Epoch: 94, Loss: 0.000423\n",
            "Epoch: 95, Loss: 0.000780\n",
            "Epoch: 96, Loss: 0.000983\n",
            "Epoch: 97, Loss: 0.000891\n",
            "Epoch: 98, Loss: 0.000426\n",
            "Epoch: 99, Loss: 0.000739\n",
            "Epoch: 100, Loss: 0.001034\n",
            "Epoch: 101, Loss: 0.000967\n",
            "Epoch: 102, Loss: 0.000674\n",
            "Epoch: 103, Loss: 0.000390\n",
            "Epoch: 104, Loss: 0.000723\n",
            "Epoch: 105, Loss: 0.000582\n",
            "Epoch: 106, Loss: 0.000712\n",
            "Epoch: 107, Loss: 0.000601\n",
            "Epoch: 108, Loss: 0.000252\n",
            "Epoch: 109, Loss: 0.000784\n",
            "Epoch: 110, Loss: 0.000207\n",
            "Epoch: 111, Loss: 0.000355\n",
            "Epoch: 112, Loss: 0.000748\n",
            "Epoch: 113, Loss: 0.000566\n",
            "Epoch: 114, Loss: 0.000739\n",
            "Epoch: 115, Loss: 0.000605\n",
            "Epoch: 116, Loss: 0.000582\n",
            "Epoch: 117, Loss: 0.000392\n",
            "Epoch: 118, Loss: 0.000593\n",
            "Epoch: 119, Loss: 0.000540\n",
            "Epoch: 120, Loss: 0.000566\n",
            "Epoch: 121, Loss: 0.000724\n",
            "Epoch: 122, Loss: 0.000348\n",
            "Epoch: 123, Loss: 0.000382\n",
            "Epoch: 124, Loss: 0.000263\n",
            "Epoch: 125, Loss: 0.000420\n",
            "Epoch: 126, Loss: 0.000742\n",
            "Epoch: 127, Loss: 0.000346\n",
            "Epoch: 128, Loss: 0.000699\n",
            "Epoch: 129, Loss: 0.000265\n",
            "Epoch: 130, Loss: 0.000551\n",
            "Epoch: 131, Loss: 0.000249\n",
            "Epoch: 132, Loss: 0.000320\n",
            "Epoch: 133, Loss: 0.000222\n",
            "Epoch: 134, Loss: 0.000374\n",
            "Epoch: 135, Loss: 0.000394\n",
            "Epoch: 136, Loss: 0.000525\n",
            "Epoch: 137, Loss: 0.000530\n",
            "Epoch: 138, Loss: 0.000534\n",
            "Epoch: 139, Loss: 0.000548\n",
            "Epoch: 140, Loss: 0.000290\n",
            "Epoch: 141, Loss: 0.000330\n",
            "Epoch: 142, Loss: 0.000376\n",
            "Epoch: 143, Loss: 0.000460\n",
            "Epoch: 144, Loss: 0.000359\n",
            "Epoch: 145, Loss: 0.000635\n",
            "Epoch: 146, Loss: 0.000365\n",
            "Epoch: 147, Loss: 0.000384\n",
            "Epoch: 148, Loss: 0.000130\n",
            "Epoch: 149, Loss: 0.000241\n",
            "Epoch: 150, Loss: 0.000299\n",
            "Epoch: 151, Loss: 0.000237\n",
            "Epoch: 152, Loss: 0.000340\n",
            "Epoch: 153, Loss: 0.000321\n",
            "Epoch: 154, Loss: 0.000379\n",
            "Epoch: 155, Loss: 0.000336\n",
            "Epoch: 156, Loss: 0.000376\n",
            "Epoch: 157, Loss: 0.000289\n",
            "Epoch: 158, Loss: 0.000376\n",
            "Epoch: 159, Loss: 0.000406\n",
            "Epoch: 160, Loss: 0.000250\n",
            "Epoch: 161, Loss: 0.000378\n",
            "Epoch: 162, Loss: 0.000179\n",
            "Epoch: 163, Loss: 0.000262\n",
            "Epoch: 164, Loss: 0.000241\n",
            "Epoch: 165, Loss: 0.000288\n",
            "Epoch: 166, Loss: 0.000287\n",
            "Epoch: 167, Loss: 0.000171\n",
            "Epoch: 168, Loss: 0.000263\n",
            "Epoch: 169, Loss: 0.000256\n",
            "Epoch: 170, Loss: 0.000213\n",
            "Epoch: 171, Loss: 0.000460\n",
            "Epoch: 172, Loss: 0.000289\n",
            "Epoch: 173, Loss: 0.000164\n",
            "Epoch: 174, Loss: 0.000377\n",
            "Epoch: 175, Loss: 0.000225\n",
            "Epoch: 176, Loss: 0.000421\n",
            "Epoch: 177, Loss: 0.000440\n",
            "Epoch: 178, Loss: 0.000269\n",
            "Epoch: 179, Loss: 0.000187\n",
            "Epoch: 180, Loss: 0.000243\n",
            "Epoch: 181, Loss: 0.000203\n",
            "Epoch: 182, Loss: 0.000252\n",
            "Epoch: 183, Loss: 0.000215\n",
            "Epoch: 184, Loss: 0.000144\n",
            "Epoch: 185, Loss: 0.000294\n",
            "Epoch: 186, Loss: 0.000206\n",
            "Epoch: 187, Loss: 0.000498\n",
            "Epoch: 188, Loss: 0.000142\n",
            "Epoch: 189, Loss: 0.000195\n",
            "Epoch: 190, Loss: 0.000316\n",
            "Epoch: 191, Loss: 0.000235\n",
            "Epoch: 192, Loss: 0.000360\n",
            "Epoch: 193, Loss: 0.000316\n",
            "Epoch: 194, Loss: 0.000202\n",
            "Epoch: 195, Loss: 0.000178\n",
            "Epoch: 196, Loss: 0.000302\n",
            "Epoch: 197, Loss: 0.000173\n",
            "Epoch: 198, Loss: 0.000234\n",
            "Epoch: 199, Loss: 0.000168\n",
            "109.32976865768433\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FBtsVSMav6X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c891b83-2ba8-4d78-9105-ff6ef55a52ae"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
        "                                           shuffle=False)\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in train_loader:\n",
        "        imgs = imgs.to(device=device)\n",
        "        labels = labels.to(device=device)\n",
        "        outputs = model(imgs.view(imgs.shape[0], -1))\n",
        "        _, predicted = torch.max(outputs, dim=1)\n",
        "        total += labels.shape[0]\n",
        "        correct += int((predicted == labels).sum())\n",
        "        \n",
        "print(\"Accuracy: %f\" % (correct / total))"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 1.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32F0b1vdav6X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd08d924-e700-4de5-b2cb-a36ccfc53f5d"
      },
      "source": [
        "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64,\n",
        "                                         shuffle=False)\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in val_loader:\n",
        "        imgs = imgs.to(device=device)\n",
        "        labels = labels.to(device=device)\n",
        "        outputs = model(imgs.view(imgs.shape[0], -1))\n",
        "        _, predicted = torch.max(outputs, dim=1)\n",
        "        total += labels.shape[0]\n",
        "        correct += int((predicted == labels).sum())\n",
        "        \n",
        "print(\"Accuracy: %f\" % (correct / total))"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.760000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-o3aIt1av6X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "585873e1-7452-43a9-a9e8-f3b83e302ca2"
      },
      "source": [
        "sum([p.numel() for p in model.parameters()])"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3737732"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWuNIH80av6X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14ab742e-8563-4b5f-8eb3-02c822fecf55"
      },
      "source": [
        "sum([p.numel() for p in model.parameters() if p.requires_grad == True])"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3737732"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_dUTPr6av6Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebf9931b-1bc7-4e31-e222-cf2058594394"
      },
      "source": [
        "first_model = nn.Sequential(\n",
        "                nn.Linear(3072, 512),\n",
        "                nn.Tanh(),\n",
        "                nn.Linear(512, 4),\n",
        "                nn.LogSoftmax(dim=1))\n",
        "\n",
        "sum([p.numel() for p in first_model.parameters()])"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1575428"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2wQdgTvav6Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a13f5421-bb66-4d2e-a082-b5bcee1d2c63"
      },
      "source": [
        "sum([p.numel() for p in nn.Linear(3072, 512).parameters()])"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1573376"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0G_OV97av6Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab7d69a3-e940-4940-bb84-1c3ce80be0d8"
      },
      "source": [
        "sum([p.numel() for p in nn.Linear(3072, 1024).parameters()])"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3146752"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFVaX10Iav6Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e027db76-19f8-4a57-cf2b-ba19acadbb80"
      },
      "source": [
        "linear = nn.Linear(3072, 1024)\n",
        "\n",
        "linear.weight.shape, linear.bias.shape"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1024, 3072]), torch.Size([1024]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4_LEga4av6Y"
      },
      "source": [
        "conv = nn.Conv2d(3, 16, kernel_size=3)"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mb2yWJZeav6Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f476eadf-f88c-4757-c0ec-b8e8c1f72a2d"
      },
      "source": [
        "conv.weight.shape"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 3, 3, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDTwMU7Qav6Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0627fa09-0cff-42f4-fc58-bbcf7fa778ad"
      },
      "source": [
        "conv.bias.shape"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SlTBwFyav6Y"
      },
      "source": [
        "img, _ = cifar2[0]\n",
        "\n",
        "output = conv(img.unsqueeze(0))"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rN-LzfOBav6Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03d14cdd-6161-42e8-f832-8960667fe1f0"
      },
      "source": [
        "img.unsqueeze(0).shape, output.shape"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 3, 32, 32]), torch.Size([1, 16, 30, 30]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_seY5p1Gav6Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "d371e617-90d0-4659-b6f9-7bef5f5b48b5"
      },
      "source": [
        "plt.imshow(img.permute(1, 2, 0), cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKX-c9YEav6Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "outputId": "165622d4-a9f3-4853-e335-c9d1099b0e36"
      },
      "source": [
        "plt.imshow(output[0, 0].detach(), cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "171vuQkqav6Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3520816e-7b03-4ad7-fece-b3a732ef082c"
      },
      "source": [
        "output.shape"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 16, 30, 30])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xiAYgD6av6Z"
      },
      "source": [
        "conv = nn.Conv2d(3, 1, kernel_size=3, padding=1)"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMkiu6LDav6Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8acc2fc-1de7-4b0c-eb82-43ecbe9643f3"
      },
      "source": [
        "output = conv(img.unsqueeze(0))\n",
        "\n",
        "output.shape"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 32, 32])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URYINj5tav6Z"
      },
      "source": [
        "with torch.no_grad():\n",
        "    conv.bias.zero_()"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0HMxkwIav6Z"
      },
      "source": [
        "with torch.no_grad():\n",
        "    conv.weight.fill_(1.0 / 9.0)"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mi5A0Ul_av6Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "outputId": "741c00e3-c2a3-41be-a097-72cd34af8daf"
      },
      "source": [
        "output = conv(img.unsqueeze(0))\n",
        "plt.imshow(output[0, 0].detach(), cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nP0oY5eav6a"
      },
      "source": [
        "conv = nn.Conv2d(3, 1, kernel_size=3, padding=1)\n",
        "\n",
        "with torch.no_grad():\n",
        "    conv.weight[:] = torch.tensor([[-1.0, 0.0, 1.0],\n",
        "                                   [-1.0, 0.0, 1.0],\n",
        "                                   [-1.0, 0.0, 1.0]])\n",
        "    conv.bias.zero_()"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaY7T5gwav6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "outputId": "5a5546c0-d57e-4f6a-e337-12b97d42cc49"
      },
      "source": [
        "output = conv(img.unsqueeze(0))\n",
        "plt.imshow(output[0, 0].detach(), cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIhg5xwjav6a"
      },
      "source": [
        "pool = nn.MaxPool2d(2)"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppktYNwRav6a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5043c2d8-19f1-40ed-c2ad-5d437e3b15fb"
      },
      "source": [
        "output = pool(img.unsqueeze(0))\n",
        "\n",
        "output.shape"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 16, 16])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Y5O2R3Eav6a"
      },
      "source": [
        ""
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhEj9m9Wav6a"
      },
      "source": [
        "model = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
        "            nn.Tanh(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(16, 8, kernel_size=3, padding=1),\n",
        "            nn.Tanh(),\n",
        "            nn.MaxPool2d(2),\n",
        "            # WARNING: something missing here\n",
        "            nn.Linear(512, 32),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(32, 4))"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_3D4GqTav6a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2110c6a1-3dd1-4d8b-ca67-0a8b911e1a7d"
      },
      "source": [
        "sum([p.numel() for p in model.parameters()])"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18156"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9tE0SVBav6a"
      },
      "source": [
        ""
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RKpRz02av6a"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
        "        self.act1 = nn.Tanh()\n",
        "        self.pool1 = nn.MaxPool2d(2)\n",
        "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
        "        self.act2 = nn.Tanh()\n",
        "        self.pool2 = nn.MaxPool2d(2)\n",
        "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
        "        self.act4 = nn.Tanh()\n",
        "        self.fc2 = nn.Linear(32, 4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.pool1(self.act1(self.conv1(x)))\n",
        "        out = self.pool2(self.act2(self.conv2(out)))\n",
        "        out = out.view(-1, 8 * 8 * 8)\n",
        "        out = self.act4(self.fc1(out))\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDVDoJptav6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73b03b29-71f0-4ead-9a9e-4db23abf033e"
      },
      "source": [
        "model = Net()\n",
        "\n",
        "sum([p.numel() for p in model.parameters()])"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18156"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSBnkEpDav6b"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
        "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
        "        self.fc2 = nn.Linear(32, 4)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
        "        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
        "        out = out.view(-1, 8 * 8 * 8)\n",
        "        out = torch.tanh(self.fc1(out))\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBEYCrJVav6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0eb4c7ae-4bf2-4cc8-8930-8942f498702a"
      },
      "source": [
        "model = Net()\n",
        "model(img.unsqueeze(0))"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1363, -0.1127, -0.1349, -0.0853]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLwLqfVEav6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bf7fe0a-5dd5-4f5c-e3ba-b04467b56436"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
        "                                           shuffle=True)\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
        "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
        "        self.fc2 = nn.Linear(32, 4)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
        "        out = F.max_pool2d(torch.relu(self.conv2(out)), 2)\n",
        "        out = out.view(-1, 8 * 8 * 8)\n",
        "        out = torch.tanh(self.fc1(out))\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "    \n",
        "model = Net().to(device=device)\n",
        "\n",
        "learning_rate = 1e-2\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "n_epochs = 200\n",
        "start=time.time()\n",
        "for epoch in range(n_epochs):\n",
        "    for imgs, labels in train_loader:\n",
        "        imgs = imgs.to(device=device)\n",
        "        labels = labels.to(device=device)\n",
        "        outputs = model(imgs)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "                \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))\n",
        "stop=time.time()\n",
        "duration= stop-start\n",
        "print(duration)"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0, Loss: 0.964538\n",
            "Epoch: 1, Loss: 0.724162\n",
            "Epoch: 2, Loss: 0.747962\n",
            "Epoch: 3, Loss: 0.706957\n",
            "Epoch: 4, Loss: 0.495163\n",
            "Epoch: 5, Loss: 0.567699\n",
            "Epoch: 6, Loss: 0.386466\n",
            "Epoch: 7, Loss: 0.638354\n",
            "Epoch: 8, Loss: 0.728167\n",
            "Epoch: 9, Loss: 0.491828\n",
            "Epoch: 10, Loss: 0.345216\n",
            "Epoch: 11, Loss: 0.608542\n",
            "Epoch: 12, Loss: 0.341203\n",
            "Epoch: 13, Loss: 0.388523\n",
            "Epoch: 14, Loss: 0.297853\n",
            "Epoch: 15, Loss: 0.304053\n",
            "Epoch: 16, Loss: 0.356352\n",
            "Epoch: 17, Loss: 0.448935\n",
            "Epoch: 18, Loss: 0.143963\n",
            "Epoch: 19, Loss: 0.336888\n",
            "Epoch: 20, Loss: 0.244590\n",
            "Epoch: 21, Loss: 0.486749\n",
            "Epoch: 22, Loss: 0.185261\n",
            "Epoch: 23, Loss: 0.384221\n",
            "Epoch: 24, Loss: 0.216494\n",
            "Epoch: 25, Loss: 0.193540\n",
            "Epoch: 26, Loss: 0.260862\n",
            "Epoch: 27, Loss: 0.338492\n",
            "Epoch: 28, Loss: 0.210572\n",
            "Epoch: 29, Loss: 0.452789\n",
            "Epoch: 30, Loss: 0.339210\n",
            "Epoch: 31, Loss: 0.392468\n",
            "Epoch: 32, Loss: 0.330184\n",
            "Epoch: 33, Loss: 0.154263\n",
            "Epoch: 34, Loss: 0.128836\n",
            "Epoch: 35, Loss: 0.224063\n",
            "Epoch: 36, Loss: 0.376281\n",
            "Epoch: 37, Loss: 0.088077\n",
            "Epoch: 38, Loss: 0.265481\n",
            "Epoch: 39, Loss: 0.149547\n",
            "Epoch: 40, Loss: 0.100602\n",
            "Epoch: 41, Loss: 0.257415\n",
            "Epoch: 42, Loss: 0.169402\n",
            "Epoch: 43, Loss: 0.120154\n",
            "Epoch: 44, Loss: 0.065142\n",
            "Epoch: 45, Loss: 0.110848\n",
            "Epoch: 46, Loss: 0.193527\n",
            "Epoch: 47, Loss: 0.102896\n",
            "Epoch: 48, Loss: 0.404394\n",
            "Epoch: 49, Loss: 0.109832\n",
            "Epoch: 50, Loss: 0.113977\n",
            "Epoch: 51, Loss: 0.065257\n",
            "Epoch: 52, Loss: 0.059369\n",
            "Epoch: 53, Loss: 0.073771\n",
            "Epoch: 54, Loss: 0.143591\n",
            "Epoch: 55, Loss: 0.243846\n",
            "Epoch: 56, Loss: 0.385194\n",
            "Epoch: 57, Loss: 0.138803\n",
            "Epoch: 58, Loss: 0.138210\n",
            "Epoch: 59, Loss: 0.291677\n",
            "Epoch: 60, Loss: 0.071370\n",
            "Epoch: 61, Loss: 0.183263\n",
            "Epoch: 62, Loss: 0.118577\n",
            "Epoch: 63, Loss: 0.060439\n",
            "Epoch: 64, Loss: 0.197362\n",
            "Epoch: 65, Loss: 0.431067\n",
            "Epoch: 66, Loss: 0.094351\n",
            "Epoch: 67, Loss: 0.034229\n",
            "Epoch: 68, Loss: 0.090011\n",
            "Epoch: 69, Loss: 0.089980\n",
            "Epoch: 70, Loss: 0.054884\n",
            "Epoch: 71, Loss: 0.105454\n",
            "Epoch: 72, Loss: 0.050647\n",
            "Epoch: 73, Loss: 0.109324\n",
            "Epoch: 74, Loss: 0.384067\n",
            "Epoch: 75, Loss: 0.097766\n",
            "Epoch: 76, Loss: 0.155045\n",
            "Epoch: 77, Loss: 0.100950\n",
            "Epoch: 78, Loss: 0.022043\n",
            "Epoch: 79, Loss: 0.071543\n",
            "Epoch: 80, Loss: 0.063986\n",
            "Epoch: 81, Loss: 0.094386\n",
            "Epoch: 82, Loss: 0.044546\n",
            "Epoch: 83, Loss: 0.171485\n",
            "Epoch: 84, Loss: 0.037446\n",
            "Epoch: 85, Loss: 0.057985\n",
            "Epoch: 86, Loss: 0.031680\n",
            "Epoch: 87, Loss: 0.023299\n",
            "Epoch: 88, Loss: 0.117570\n",
            "Epoch: 89, Loss: 0.077504\n",
            "Epoch: 90, Loss: 0.061603\n",
            "Epoch: 91, Loss: 0.028931\n",
            "Epoch: 92, Loss: 0.032096\n",
            "Epoch: 93, Loss: 0.039861\n",
            "Epoch: 94, Loss: 0.222897\n",
            "Epoch: 95, Loss: 0.084085\n",
            "Epoch: 96, Loss: 0.016941\n",
            "Epoch: 97, Loss: 0.057337\n",
            "Epoch: 98, Loss: 0.022104\n",
            "Epoch: 99, Loss: 0.022809\n",
            "Epoch: 100, Loss: 0.030823\n",
            "Epoch: 101, Loss: 0.033784\n",
            "Epoch: 102, Loss: 0.015065\n",
            "Epoch: 103, Loss: 0.020855\n",
            "Epoch: 104, Loss: 0.018918\n",
            "Epoch: 105, Loss: 0.020954\n",
            "Epoch: 106, Loss: 0.023256\n",
            "Epoch: 107, Loss: 0.041368\n",
            "Epoch: 108, Loss: 0.023042\n",
            "Epoch: 109, Loss: 0.028908\n",
            "Epoch: 110, Loss: 0.021116\n",
            "Epoch: 111, Loss: 0.086932\n",
            "Epoch: 112, Loss: 0.023409\n",
            "Epoch: 113, Loss: 0.003312\n",
            "Epoch: 114, Loss: 0.054088\n",
            "Epoch: 115, Loss: 0.018313\n",
            "Epoch: 116, Loss: 0.032817\n",
            "Epoch: 117, Loss: 0.046866\n",
            "Epoch: 118, Loss: 0.035803\n",
            "Epoch: 119, Loss: 0.029006\n",
            "Epoch: 120, Loss: 0.050095\n",
            "Epoch: 121, Loss: 0.012307\n",
            "Epoch: 122, Loss: 0.018390\n",
            "Epoch: 123, Loss: 0.015453\n",
            "Epoch: 124, Loss: 0.013493\n",
            "Epoch: 125, Loss: 0.087426\n",
            "Epoch: 126, Loss: 0.020163\n",
            "Epoch: 127, Loss: 0.012792\n",
            "Epoch: 128, Loss: 0.043655\n",
            "Epoch: 129, Loss: 0.020054\n",
            "Epoch: 130, Loss: 0.022352\n",
            "Epoch: 131, Loss: 0.070918\n",
            "Epoch: 132, Loss: 0.083513\n",
            "Epoch: 133, Loss: 0.077547\n",
            "Epoch: 134, Loss: 0.019590\n",
            "Epoch: 135, Loss: 0.007852\n",
            "Epoch: 136, Loss: 0.024403\n",
            "Epoch: 137, Loss: 0.028301\n",
            "Epoch: 138, Loss: 0.030920\n",
            "Epoch: 139, Loss: 0.014456\n",
            "Epoch: 140, Loss: 0.019373\n",
            "Epoch: 141, Loss: 0.017821\n",
            "Epoch: 142, Loss: 0.010950\n",
            "Epoch: 143, Loss: 0.150103\n",
            "Epoch: 144, Loss: 0.025437\n",
            "Epoch: 145, Loss: 0.043801\n",
            "Epoch: 146, Loss: 0.005371\n",
            "Epoch: 147, Loss: 0.006602\n",
            "Epoch: 148, Loss: 0.012566\n",
            "Epoch: 149, Loss: 0.026164\n",
            "Epoch: 150, Loss: 0.018666\n",
            "Epoch: 151, Loss: 0.008990\n",
            "Epoch: 152, Loss: 0.015164\n",
            "Epoch: 153, Loss: 0.021507\n",
            "Epoch: 154, Loss: 0.017322\n",
            "Epoch: 155, Loss: 0.011532\n",
            "Epoch: 156, Loss: 0.019694\n",
            "Epoch: 157, Loss: 0.007389\n",
            "Epoch: 158, Loss: 0.006954\n",
            "Epoch: 159, Loss: 0.007758\n",
            "Epoch: 160, Loss: 0.009871\n",
            "Epoch: 161, Loss: 0.003685\n",
            "Epoch: 162, Loss: 0.026212\n",
            "Epoch: 163, Loss: 0.024858\n",
            "Epoch: 164, Loss: 0.012327\n",
            "Epoch: 165, Loss: 0.012566\n",
            "Epoch: 166, Loss: 0.031120\n",
            "Epoch: 167, Loss: 0.007268\n",
            "Epoch: 168, Loss: 0.033327\n",
            "Epoch: 169, Loss: 0.009463\n",
            "Epoch: 170, Loss: 0.013696\n",
            "Epoch: 171, Loss: 0.041311\n",
            "Epoch: 172, Loss: 0.004904\n",
            "Epoch: 173, Loss: 0.011339\n",
            "Epoch: 174, Loss: 0.007507\n",
            "Epoch: 175, Loss: 0.055493\n",
            "Epoch: 176, Loss: 0.003036\n",
            "Epoch: 177, Loss: 0.009776\n",
            "Epoch: 178, Loss: 0.010612\n",
            "Epoch: 179, Loss: 0.006798\n",
            "Epoch: 180, Loss: 0.006390\n",
            "Epoch: 181, Loss: 0.024922\n",
            "Epoch: 182, Loss: 0.006513\n",
            "Epoch: 183, Loss: 0.010178\n",
            "Epoch: 184, Loss: 0.006640\n",
            "Epoch: 185, Loss: 0.002605\n",
            "Epoch: 186, Loss: 0.004657\n",
            "Epoch: 187, Loss: 0.003673\n",
            "Epoch: 188, Loss: 0.008314\n",
            "Epoch: 189, Loss: 0.007519\n",
            "Epoch: 190, Loss: 0.006360\n",
            "Epoch: 191, Loss: 0.004467\n",
            "Epoch: 192, Loss: 0.004553\n",
            "Epoch: 193, Loss: 0.007832\n",
            "Epoch: 194, Loss: 0.007269\n",
            "Epoch: 195, Loss: 0.008391\n",
            "Epoch: 196, Loss: 0.003310\n",
            "Epoch: 197, Loss: 0.016790\n",
            "Epoch: 198, Loss: 0.010222\n",
            "Epoch: 199, Loss: 0.010616\n",
            "125.15874695777893\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sPj1Lesav6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6f13b08-78bc-49c3-edff-0bab157bffe4"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
        "                                           shuffle=False)\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in train_loader:\n",
        "        imgs = imgs.to(device=device)\n",
        "        labels = labels.to(device=device)\n",
        "        outputs = model(imgs)\n",
        "        _, predicted = torch.max(outputs, dim=1)\n",
        "        total += labels.shape[0]\n",
        "        correct += int((predicted == labels).sum())\n",
        "        \n",
        "print(\"Accuracy: %f\" % (correct / total))"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.998350\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIBg2b6lav6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5149f125-8ba7-4786-bdd5-a6c92fa2600e"
      },
      "source": [
        "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64,\n",
        "                                         shuffle=False)\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in val_loader:\n",
        "        imgs = imgs.to(device=device)\n",
        "        labels = labels.to(device=device)\n",
        "        outputs = model(imgs)\n",
        "        _, predicted = torch.max(outputs, dim=1)\n",
        "        total += labels.shape[0]\n",
        "        correct += int((predicted == labels).sum())\n",
        "        \n",
        "print(\"Accuracy: %f\" % (correct / total))"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.893250\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svAMYExHav6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7b8cb44-9227-4e1b-db33-7deffc332325"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
        "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
        "        self.fc2 = nn.Linear(32, 4)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
        "        out = F.max_pool2d(torch.relu(self.conv2(out)), 2)\n",
        "        out = out.view(-1, 8 * 8 * 8)\n",
        "        out = torch.tanh(self.fc1(out))\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "    \n",
        "model = Net()\n",
        "sum([p.numel() for p in model.parameters()])"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18156"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_QXTkLrav6b"
      },
      "source": [
        "label_map = {0:1,1:2,2:3,3:4,4:5,5:6,6:7,7:8,8:9,9:10}\n",
        "class_names = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']\n",
        "cifar2 = [(img, label_map[label])\n",
        "          for img, label in cifar10 \n",
        "          if label in [0,1,2,3,4,5,6,7,8,9]]\n",
        "cifar2_val = [(img, label_map[label])\n",
        "              for img, label in cifar10_val\n",
        "              if label in [0,1,2,3,4,5,6,7,8,9]]"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGSoGkaZIOGo"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
        "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
        "        self.fc2 = nn.Linear(32, 11)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
        "        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
        "        out = out.view(-1, 8 * 8 * 8)\n",
        "        out = torch.tanh(self.fc1(out))\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epG5N2bXIZcN",
        "outputId": "da6939b3-2ae8-4b28-ac98-1d318860ca5b"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
        "                                           shuffle=True)\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
        "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
        "        self.fc2 = nn.Linear(32, 11)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
        "        out = F.max_pool2d(torch.relu(self.conv2(out)), 2)\n",
        "        out = out.view(-1, 8 * 8 * 8)\n",
        "        out = torch.tanh(self.fc1(out))\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "    \n",
        "model = Net().to(device=device)\n",
        "\n",
        "learning_rate = 1e-2\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "n_epochs = 200\n",
        "start=time.time()\n",
        "for epoch in range(n_epochs):\n",
        "    for imgs, labels in train_loader:\n",
        "        imgs = imgs.to(device=device)\n",
        "        labels = labels.to(device=device)\n",
        "        outputs = model(imgs)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "                \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))\n",
        "stop=time.time()\n",
        "duration= stop-start\n",
        "print(duration)"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0, Loss: 1.630632\n",
            "Epoch: 1, Loss: 1.626038\n",
            "Epoch: 2, Loss: 1.473959\n",
            "Epoch: 3, Loss: 1.014542\n",
            "Epoch: 4, Loss: 1.309493\n",
            "Epoch: 5, Loss: 1.452033\n",
            "Epoch: 6, Loss: 0.984312\n",
            "Epoch: 7, Loss: 1.058070\n",
            "Epoch: 8, Loss: 1.234672\n",
            "Epoch: 9, Loss: 1.363614\n",
            "Epoch: 10, Loss: 1.229454\n",
            "Epoch: 11, Loss: 1.573955\n",
            "Epoch: 12, Loss: 1.040215\n",
            "Epoch: 13, Loss: 0.997568\n",
            "Epoch: 14, Loss: 1.200594\n",
            "Epoch: 15, Loss: 0.687044\n",
            "Epoch: 16, Loss: 0.784708\n",
            "Epoch: 17, Loss: 1.193579\n",
            "Epoch: 18, Loss: 0.966077\n",
            "Epoch: 19, Loss: 0.866512\n",
            "Epoch: 20, Loss: 0.907054\n",
            "Epoch: 21, Loss: 0.967395\n",
            "Epoch: 22, Loss: 1.111829\n",
            "Epoch: 23, Loss: 0.850336\n",
            "Epoch: 24, Loss: 0.974863\n",
            "Epoch: 25, Loss: 0.825736\n",
            "Epoch: 26, Loss: 1.006421\n",
            "Epoch: 27, Loss: 1.136679\n",
            "Epoch: 28, Loss: 1.106830\n",
            "Epoch: 29, Loss: 0.985275\n",
            "Epoch: 30, Loss: 0.463608\n",
            "Epoch: 31, Loss: 0.740429\n",
            "Epoch: 32, Loss: 1.185346\n",
            "Epoch: 33, Loss: 0.788887\n",
            "Epoch: 34, Loss: 1.607178\n",
            "Epoch: 35, Loss: 0.955403\n",
            "Epoch: 36, Loss: 0.809623\n",
            "Epoch: 37, Loss: 1.026389\n",
            "Epoch: 38, Loss: 0.759034\n",
            "Epoch: 39, Loss: 0.647634\n",
            "Epoch: 40, Loss: 0.905032\n",
            "Epoch: 41, Loss: 1.020274\n",
            "Epoch: 42, Loss: 1.004238\n",
            "Epoch: 43, Loss: 0.852024\n",
            "Epoch: 44, Loss: 0.676200\n",
            "Epoch: 45, Loss: 0.662873\n",
            "Epoch: 46, Loss: 1.095437\n",
            "Epoch: 47, Loss: 0.792836\n",
            "Epoch: 48, Loss: 0.847426\n",
            "Epoch: 49, Loss: 0.604386\n",
            "Epoch: 50, Loss: 0.958202\n",
            "Epoch: 51, Loss: 0.368288\n",
            "Epoch: 52, Loss: 0.481525\n",
            "Epoch: 53, Loss: 0.711409\n",
            "Epoch: 54, Loss: 0.971635\n",
            "Epoch: 55, Loss: 0.803595\n",
            "Epoch: 56, Loss: 0.782283\n",
            "Epoch: 57, Loss: 0.490061\n",
            "Epoch: 58, Loss: 0.536608\n",
            "Epoch: 59, Loss: 0.853467\n",
            "Epoch: 60, Loss: 0.721551\n",
            "Epoch: 61, Loss: 0.428250\n",
            "Epoch: 62, Loss: 0.398801\n",
            "Epoch: 63, Loss: 0.789172\n",
            "Epoch: 64, Loss: 0.350363\n",
            "Epoch: 65, Loss: 1.115459\n",
            "Epoch: 66, Loss: 1.361266\n",
            "Epoch: 67, Loss: 1.255412\n",
            "Epoch: 68, Loss: 0.564192\n",
            "Epoch: 69, Loss: 0.436549\n",
            "Epoch: 70, Loss: 0.937413\n",
            "Epoch: 71, Loss: 1.240954\n",
            "Epoch: 72, Loss: 0.713515\n",
            "Epoch: 73, Loss: 0.664266\n",
            "Epoch: 74, Loss: 0.792530\n",
            "Epoch: 75, Loss: 0.890128\n",
            "Epoch: 76, Loss: 0.759067\n",
            "Epoch: 77, Loss: 0.821808\n",
            "Epoch: 78, Loss: 0.593517\n",
            "Epoch: 79, Loss: 1.066600\n",
            "Epoch: 80, Loss: 1.239662\n",
            "Epoch: 81, Loss: 0.774361\n",
            "Epoch: 82, Loss: 0.390010\n",
            "Epoch: 83, Loss: 0.964416\n",
            "Epoch: 84, Loss: 1.085132\n",
            "Epoch: 85, Loss: 0.747433\n",
            "Epoch: 86, Loss: 1.023928\n",
            "Epoch: 87, Loss: 0.423112\n",
            "Epoch: 88, Loss: 1.091587\n",
            "Epoch: 89, Loss: 0.482871\n",
            "Epoch: 90, Loss: 0.635011\n",
            "Epoch: 91, Loss: 0.468776\n",
            "Epoch: 92, Loss: 0.493218\n",
            "Epoch: 93, Loss: 0.867923\n",
            "Epoch: 94, Loss: 0.620053\n",
            "Epoch: 95, Loss: 1.781363\n",
            "Epoch: 96, Loss: 1.129022\n",
            "Epoch: 97, Loss: 1.030645\n",
            "Epoch: 98, Loss: 0.271970\n",
            "Epoch: 99, Loss: 0.735519\n",
            "Epoch: 100, Loss: 0.577851\n",
            "Epoch: 101, Loss: 0.608651\n",
            "Epoch: 102, Loss: 0.393906\n",
            "Epoch: 103, Loss: 0.667262\n",
            "Epoch: 104, Loss: 0.569054\n",
            "Epoch: 105, Loss: 0.525331\n",
            "Epoch: 106, Loss: 0.971918\n",
            "Epoch: 107, Loss: 0.810839\n",
            "Epoch: 108, Loss: 0.687702\n",
            "Epoch: 109, Loss: 0.631258\n",
            "Epoch: 110, Loss: 1.221375\n",
            "Epoch: 111, Loss: 0.714578\n",
            "Epoch: 112, Loss: 0.773356\n",
            "Epoch: 113, Loss: 0.970697\n",
            "Epoch: 114, Loss: 0.694017\n",
            "Epoch: 115, Loss: 0.708794\n",
            "Epoch: 116, Loss: 0.634752\n",
            "Epoch: 117, Loss: 1.011657\n",
            "Epoch: 118, Loss: 0.823846\n",
            "Epoch: 119, Loss: 1.136559\n",
            "Epoch: 120, Loss: 0.460762\n",
            "Epoch: 121, Loss: 0.285339\n",
            "Epoch: 122, Loss: 0.609543\n",
            "Epoch: 123, Loss: 0.731917\n",
            "Epoch: 124, Loss: 0.334039\n",
            "Epoch: 125, Loss: 0.664728\n",
            "Epoch: 126, Loss: 0.986010\n",
            "Epoch: 127, Loss: 0.478359\n",
            "Epoch: 128, Loss: 0.207851\n",
            "Epoch: 129, Loss: 0.556501\n",
            "Epoch: 130, Loss: 0.696734\n",
            "Epoch: 131, Loss: 0.369567\n",
            "Epoch: 132, Loss: 0.446363\n",
            "Epoch: 133, Loss: 0.681634\n",
            "Epoch: 134, Loss: 0.545506\n",
            "Epoch: 135, Loss: 0.777489\n",
            "Epoch: 136, Loss: 0.785830\n",
            "Epoch: 137, Loss: 0.528228\n",
            "Epoch: 138, Loss: 0.753022\n",
            "Epoch: 139, Loss: 0.474088\n",
            "Epoch: 140, Loss: 0.417510\n",
            "Epoch: 141, Loss: 0.716990\n",
            "Epoch: 142, Loss: 0.239441\n",
            "Epoch: 143, Loss: 0.554899\n",
            "Epoch: 144, Loss: 0.936544\n",
            "Epoch: 145, Loss: 0.748122\n",
            "Epoch: 146, Loss: 0.825913\n",
            "Epoch: 147, Loss: 0.404696\n",
            "Epoch: 148, Loss: 0.763083\n",
            "Epoch: 149, Loss: 0.577315\n",
            "Epoch: 150, Loss: 0.423159\n",
            "Epoch: 151, Loss: 0.631814\n",
            "Epoch: 152, Loss: 0.717583\n",
            "Epoch: 153, Loss: 0.423514\n",
            "Epoch: 154, Loss: 0.327239\n",
            "Epoch: 155, Loss: 0.516500\n",
            "Epoch: 156, Loss: 1.084187\n",
            "Epoch: 157, Loss: 0.520892\n",
            "Epoch: 158, Loss: 0.994687\n",
            "Epoch: 159, Loss: 0.470083\n",
            "Epoch: 160, Loss: 0.519242\n",
            "Epoch: 161, Loss: 1.091684\n",
            "Epoch: 162, Loss: 0.511956\n",
            "Epoch: 163, Loss: 0.751553\n",
            "Epoch: 164, Loss: 0.505283\n",
            "Epoch: 165, Loss: 0.756595\n",
            "Epoch: 166, Loss: 0.672741\n",
            "Epoch: 167, Loss: 0.568668\n",
            "Epoch: 168, Loss: 0.527794\n",
            "Epoch: 169, Loss: 0.520113\n",
            "Epoch: 170, Loss: 0.463996\n",
            "Epoch: 171, Loss: 1.662685\n",
            "Epoch: 172, Loss: 0.852148\n",
            "Epoch: 173, Loss: 0.743566\n",
            "Epoch: 174, Loss: 0.267283\n",
            "Epoch: 175, Loss: 0.303889\n",
            "Epoch: 176, Loss: 0.403189\n",
            "Epoch: 177, Loss: 0.239180\n",
            "Epoch: 178, Loss: 0.483372\n",
            "Epoch: 179, Loss: 1.207420\n",
            "Epoch: 180, Loss: 0.327204\n",
            "Epoch: 181, Loss: 0.547137\n",
            "Epoch: 182, Loss: 0.498454\n",
            "Epoch: 183, Loss: 0.393527\n",
            "Epoch: 184, Loss: 0.581552\n",
            "Epoch: 185, Loss: 0.765098\n",
            "Epoch: 186, Loss: 0.327874\n",
            "Epoch: 187, Loss: 0.716726\n",
            "Epoch: 188, Loss: 0.310866\n",
            "Epoch: 189, Loss: 0.290690\n",
            "Epoch: 190, Loss: 0.354156\n",
            "Epoch: 191, Loss: 1.200847\n",
            "Epoch: 192, Loss: 0.688901\n",
            "Epoch: 193, Loss: 0.622787\n",
            "Epoch: 194, Loss: 0.255119\n",
            "Epoch: 195, Loss: 0.223256\n",
            "Epoch: 196, Loss: 0.741649\n",
            "Epoch: 197, Loss: 0.695497\n",
            "Epoch: 198, Loss: 1.487280\n",
            "Epoch: 199, Loss: 0.744646\n",
            "311.1102707386017\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRBksrQeWKCy",
        "outputId": "21b6c6db-e3bc-418b-c5f1-bafc342b490e"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
        "                                           shuffle=False)\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in train_loader:\n",
        "        imgs = imgs.to(device=device)\n",
        "        labels = labels.to(device=device)\n",
        "        outputs = model(imgs)\n",
        "        _, predicted = torch.max(outputs, dim=1)\n",
        "        total += labels.shape[0]\n",
        "        correct += int((predicted == labels).sum())\n",
        "        \n",
        "print(\"Accuracy: %f\" % (correct / total))"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.793160\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5K2DnSJWUQk",
        "outputId": "97117615-dcc4-4857-87e0-2599f222327b"
      },
      "source": [
        "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64,\n",
        "                                         shuffle=False)\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in val_loader:\n",
        "        imgs = imgs.to(device=device)\n",
        "        labels = labels.to(device=device)\n",
        "        outputs = model(imgs)\n",
        "        _, predicted = torch.max(outputs, dim=1)\n",
        "        total += labels.shape[0]\n",
        "        correct += int((predicted == labels).sum())\n",
        "        \n",
        "print(\"Accuracy: %f\" % (correct / total))"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.605700\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHsJPjoyXedk",
        "outputId": "8ab9146c-0773-447d-d8ea-c0e73f24144e"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
        "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
        "        self.fc2 = nn.Linear(32, 11)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
        "        out = F.max_pool2d(torch.relu(self.conv2(out)), 2)\n",
        "        out = out.view(-1, 8 * 8 * 8)\n",
        "        out = torch.tanh(self.fc1(out))\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "    \n",
        "model = Net()\n",
        "sum([p.numel() for p in model.parameters()])"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18387"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ynBHy7EOiUO",
        "outputId": "a61f04c3-e8bd-46a9-c85d-6a6a94fa8aef"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
        "                                           shuffle=True)\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 16, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(16, 16, kernel_size=3, padding=1)\n",
        "        self.fc1 = nn.Linear( 4* 4 * 16, 32)\n",
        "        self.fc2 = nn.Linear(32, 11)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
        "        out = F.max_pool2d(torch.relu(self.conv2(out)), 2)\n",
        "        out = F.max_pool2d(torch.relu(self.conv3(out)), 2)\n",
        "        \n",
        "        out = out.view(-1, 4 * 4* 16)\n",
        "        out = torch.tanh(self.fc1(out))\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "    \n",
        "model = Net().to(device=device)\n",
        "\n",
        "learning_rate = 1e-2\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "n_epochs = 200\n",
        "start=time.time()\n",
        "for epoch in range(n_epochs):\n",
        "    for imgs, labels in train_loader:\n",
        "      imgs = imgs.to(device=device)\n",
        "      labels = labels.to(device=device)\n",
        "      outputs = model(imgs)\n",
        "      loss = loss_fn(outputs, labels)\n",
        "                \n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "    print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))\n",
        "stop=time.time()\n",
        "duration= stop-start\n",
        "print(duration)"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0, Loss: 1.815450\n",
            "Epoch: 1, Loss: 1.774333\n",
            "Epoch: 2, Loss: 1.412293\n",
            "Epoch: 3, Loss: 1.370417\n",
            "Epoch: 4, Loss: 1.456674\n",
            "Epoch: 5, Loss: 1.318353\n",
            "Epoch: 6, Loss: 1.207792\n",
            "Epoch: 7, Loss: 1.057680\n",
            "Epoch: 8, Loss: 1.056420\n",
            "Epoch: 9, Loss: 1.383750\n",
            "Epoch: 10, Loss: 0.842261\n",
            "Epoch: 11, Loss: 0.998506\n",
            "Epoch: 12, Loss: 1.673004\n",
            "Epoch: 13, Loss: 1.144144\n",
            "Epoch: 14, Loss: 0.939932\n",
            "Epoch: 15, Loss: 0.854558\n",
            "Epoch: 16, Loss: 1.076940\n",
            "Epoch: 17, Loss: 1.116426\n",
            "Epoch: 18, Loss: 0.966814\n",
            "Epoch: 19, Loss: 0.837389\n",
            "Epoch: 20, Loss: 0.772777\n",
            "Epoch: 21, Loss: 0.987383\n",
            "Epoch: 22, Loss: 0.610867\n",
            "Epoch: 23, Loss: 0.979771\n",
            "Epoch: 24, Loss: 0.486308\n",
            "Epoch: 25, Loss: 0.939357\n",
            "Epoch: 26, Loss: 0.481328\n",
            "Epoch: 27, Loss: 1.017589\n",
            "Epoch: 28, Loss: 0.849248\n",
            "Epoch: 29, Loss: 0.738298\n",
            "Epoch: 30, Loss: 0.400650\n",
            "Epoch: 31, Loss: 0.532152\n",
            "Epoch: 32, Loss: 0.565460\n",
            "Epoch: 33, Loss: 0.860892\n",
            "Epoch: 34, Loss: 0.415114\n",
            "Epoch: 35, Loss: 0.646673\n",
            "Epoch: 36, Loss: 0.603723\n",
            "Epoch: 37, Loss: 0.987874\n",
            "Epoch: 38, Loss: 0.904717\n",
            "Epoch: 39, Loss: 0.673593\n",
            "Epoch: 40, Loss: 0.675331\n",
            "Epoch: 41, Loss: 0.697591\n",
            "Epoch: 42, Loss: 0.586442\n",
            "Epoch: 43, Loss: 0.781747\n",
            "Epoch: 44, Loss: 0.998519\n",
            "Epoch: 45, Loss: 1.145496\n",
            "Epoch: 46, Loss: 0.884872\n",
            "Epoch: 47, Loss: 1.485489\n",
            "Epoch: 48, Loss: 0.683416\n",
            "Epoch: 49, Loss: 0.890194\n",
            "Epoch: 50, Loss: 0.481758\n",
            "Epoch: 51, Loss: 1.014521\n",
            "Epoch: 52, Loss: 0.245946\n",
            "Epoch: 53, Loss: 0.673497\n",
            "Epoch: 54, Loss: 0.677806\n",
            "Epoch: 55, Loss: 0.643022\n",
            "Epoch: 56, Loss: 0.766825\n",
            "Epoch: 57, Loss: 0.476301\n",
            "Epoch: 58, Loss: 0.538511\n",
            "Epoch: 59, Loss: 0.457873\n",
            "Epoch: 60, Loss: 0.741542\n",
            "Epoch: 61, Loss: 0.501815\n",
            "Epoch: 62, Loss: 0.521666\n",
            "Epoch: 63, Loss: 0.668466\n",
            "Epoch: 64, Loss: 0.819792\n",
            "Epoch: 65, Loss: 0.632047\n",
            "Epoch: 66, Loss: 0.440327\n",
            "Epoch: 67, Loss: 0.812687\n",
            "Epoch: 68, Loss: 0.556032\n",
            "Epoch: 69, Loss: 0.979247\n",
            "Epoch: 70, Loss: 0.438927\n",
            "Epoch: 71, Loss: 0.666600\n",
            "Epoch: 72, Loss: 0.576571\n",
            "Epoch: 73, Loss: 0.460111\n",
            "Epoch: 74, Loss: 0.674226\n",
            "Epoch: 75, Loss: 0.250418\n",
            "Epoch: 76, Loss: 0.673608\n",
            "Epoch: 77, Loss: 0.649806\n",
            "Epoch: 78, Loss: 0.588425\n",
            "Epoch: 79, Loss: 0.749631\n",
            "Epoch: 80, Loss: 0.772557\n",
            "Epoch: 81, Loss: 0.360243\n",
            "Epoch: 82, Loss: 0.402461\n",
            "Epoch: 83, Loss: 0.347161\n",
            "Epoch: 84, Loss: 0.645017\n",
            "Epoch: 85, Loss: 0.502582\n",
            "Epoch: 86, Loss: 0.875821\n",
            "Epoch: 87, Loss: 0.747584\n",
            "Epoch: 88, Loss: 0.555686\n",
            "Epoch: 89, Loss: 0.736777\n",
            "Epoch: 90, Loss: 0.471219\n",
            "Epoch: 91, Loss: 0.570371\n",
            "Epoch: 92, Loss: 0.473156\n",
            "Epoch: 93, Loss: 0.345340\n",
            "Epoch: 94, Loss: 0.332614\n",
            "Epoch: 95, Loss: 0.282035\n",
            "Epoch: 96, Loss: 0.293592\n",
            "Epoch: 97, Loss: 0.939425\n",
            "Epoch: 98, Loss: 0.944347\n",
            "Epoch: 99, Loss: 0.929389\n",
            "Epoch: 100, Loss: 0.274769\n",
            "Epoch: 101, Loss: 0.786705\n",
            "Epoch: 102, Loss: 0.242521\n",
            "Epoch: 103, Loss: 0.527716\n",
            "Epoch: 104, Loss: 0.440095\n",
            "Epoch: 105, Loss: 0.497663\n",
            "Epoch: 106, Loss: 0.926447\n",
            "Epoch: 107, Loss: 0.615851\n",
            "Epoch: 108, Loss: 1.087442\n",
            "Epoch: 109, Loss: 0.846562\n",
            "Epoch: 110, Loss: 0.308036\n",
            "Epoch: 111, Loss: 0.743445\n",
            "Epoch: 112, Loss: 0.231890\n",
            "Epoch: 113, Loss: 0.761168\n",
            "Epoch: 114, Loss: 0.729521\n",
            "Epoch: 115, Loss: 0.508001\n",
            "Epoch: 116, Loss: 0.481892\n",
            "Epoch: 117, Loss: 0.425660\n",
            "Epoch: 118, Loss: 0.493841\n",
            "Epoch: 119, Loss: 0.232314\n",
            "Epoch: 120, Loss: 0.563952\n",
            "Epoch: 121, Loss: 0.378136\n",
            "Epoch: 122, Loss: 0.741829\n",
            "Epoch: 123, Loss: 0.515470\n",
            "Epoch: 124, Loss: 0.274547\n",
            "Epoch: 125, Loss: 0.355533\n",
            "Epoch: 126, Loss: 0.187323\n",
            "Epoch: 127, Loss: 0.573579\n",
            "Epoch: 128, Loss: 0.540879\n",
            "Epoch: 129, Loss: 1.037601\n",
            "Epoch: 130, Loss: 0.612478\n",
            "Epoch: 131, Loss: 0.842163\n",
            "Epoch: 132, Loss: 0.429418\n",
            "Epoch: 133, Loss: 1.138260\n",
            "Epoch: 134, Loss: 0.621828\n",
            "Epoch: 135, Loss: 0.531976\n",
            "Epoch: 136, Loss: 0.371266\n",
            "Epoch: 137, Loss: 0.376345\n",
            "Epoch: 138, Loss: 0.605312\n",
            "Epoch: 139, Loss: 0.992835\n",
            "Epoch: 140, Loss: 0.557489\n",
            "Epoch: 141, Loss: 0.667454\n",
            "Epoch: 142, Loss: 0.799015\n",
            "Epoch: 143, Loss: 0.618220\n",
            "Epoch: 144, Loss: 0.617208\n",
            "Epoch: 145, Loss: 0.546680\n",
            "Epoch: 146, Loss: 0.443525\n",
            "Epoch: 147, Loss: 0.524242\n",
            "Epoch: 148, Loss: 0.443278\n",
            "Epoch: 149, Loss: 1.117697\n",
            "Epoch: 150, Loss: 0.251454\n",
            "Epoch: 151, Loss: 0.772632\n",
            "Epoch: 152, Loss: 0.528361\n",
            "Epoch: 153, Loss: 0.697093\n",
            "Epoch: 154, Loss: 0.743009\n",
            "Epoch: 155, Loss: 0.557216\n",
            "Epoch: 156, Loss: 0.520070\n",
            "Epoch: 157, Loss: 0.397028\n",
            "Epoch: 158, Loss: 0.455906\n",
            "Epoch: 159, Loss: 0.526003\n",
            "Epoch: 160, Loss: 0.279000\n",
            "Epoch: 161, Loss: 0.501443\n",
            "Epoch: 162, Loss: 0.551975\n",
            "Epoch: 163, Loss: 0.377460\n",
            "Epoch: 164, Loss: 0.345294\n",
            "Epoch: 165, Loss: 0.396593\n",
            "Epoch: 166, Loss: 0.343571\n",
            "Epoch: 167, Loss: 0.457767\n",
            "Epoch: 168, Loss: 0.393956\n",
            "Epoch: 169, Loss: 1.050932\n",
            "Epoch: 170, Loss: 1.252817\n",
            "Epoch: 171, Loss: 0.267416\n",
            "Epoch: 172, Loss: 0.653474\n",
            "Epoch: 173, Loss: 0.213585\n",
            "Epoch: 174, Loss: 0.425839\n",
            "Epoch: 175, Loss: 0.198822\n",
            "Epoch: 176, Loss: 0.426481\n",
            "Epoch: 177, Loss: 0.735873\n",
            "Epoch: 178, Loss: 0.492256\n",
            "Epoch: 179, Loss: 0.533843\n",
            "Epoch: 180, Loss: 0.206743\n",
            "Epoch: 181, Loss: 0.900810\n",
            "Epoch: 182, Loss: 0.627026\n",
            "Epoch: 183, Loss: 0.407781\n",
            "Epoch: 184, Loss: 0.673141\n",
            "Epoch: 185, Loss: 0.956752\n",
            "Epoch: 186, Loss: 0.573016\n",
            "Epoch: 187, Loss: 0.392009\n",
            "Epoch: 188, Loss: 0.680911\n",
            "Epoch: 189, Loss: 0.439284\n",
            "Epoch: 190, Loss: 0.577723\n",
            "Epoch: 191, Loss: 0.745340\n",
            "Epoch: 192, Loss: 1.155561\n",
            "Epoch: 193, Loss: 0.204835\n",
            "Epoch: 194, Loss: 0.765677\n",
            "Epoch: 195, Loss: 0.189167\n",
            "Epoch: 196, Loss: 0.556812\n",
            "Epoch: 197, Loss: 0.513253\n",
            "Epoch: 198, Loss: 0.210842\n",
            "Epoch: 199, Loss: 0.171842\n",
            "356.926246881485\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lc9g3z47sq8f",
        "outputId": "e617cf5a-26ad-4df8-8df0-7c1ac1c35415"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
        "                                           shuffle=False)\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in train_loader:\n",
        "        imgs = imgs.to(device=device)\n",
        "        labels = labels.to(device=device)\n",
        "        outputs = model(imgs)\n",
        "        _, predicted = torch.max(outputs, dim=1)\n",
        "        total += labels.shape[0]\n",
        "        correct += int((predicted == labels).sum())\n",
        "        \n",
        "print(\"Accuracy: %f\" % (correct / total))"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.833980\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQdmdFbLX9Is",
        "outputId": "025d5d53-b9d4-49ff-87fa-2f842e549215"
      },
      "source": [
        "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64,\n",
        "                                         shuffle=False)\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in val_loader:\n",
        "        imgs = imgs.to(device=device)\n",
        "        labels = labels.to(device=device)\n",
        "        outputs = model(imgs)\n",
        "        _, predicted = torch.max(outputs, dim=1)\n",
        "        total += labels.shape[0]\n",
        "        correct += int((predicted == labels).sum())\n",
        "        \n",
        "print(\"Accuracy: %f\" % (correct / total))"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.682800\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BU1af8UBYRtt",
        "outputId": "f467f588-5ae4-4cb4-ffd0-2483a178ab54"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 16, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(16, 16, kernel_size=3, padding=1)\n",
        "        self.fc1 = nn.Linear( 4* 4 * 16, 32)\n",
        "        self.fc2 = nn.Linear(32, 11)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
        "        out = F.max_pool2d(torch.relu(self.conv2(out)), 2)\n",
        "        out = F.max_pool2d(torch.relu(self.conv3(out)), 2)\n",
        "        \n",
        "        out = out.view(-1, 4 * 4* 16)\n",
        "        out = torch.tanh(self.fc1(out))\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "    \n",
        "model = Net()\n",
        "sum([p.numel() for p in model.parameters()])\n"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16427"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    }
  ]
}